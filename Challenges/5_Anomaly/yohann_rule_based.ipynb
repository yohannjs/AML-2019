{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook of task](https://github.com/DistributedSystemsGroup/Algorithmic-Machine-Learning/blob/master/Challenges/Anomaly_Detection/anomaly_detection_challenge.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a8/66fbb303236eb7e4caa63096814aa2675073f20aee95104920636af84a7e/fim-6.27.tar.gz (343kB)\n",
      "\u001b[K    100% |################################| 348kB 1.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: fim\n",
      "  Running setup.py bdist_wheel for fim ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /mnt/workspace/.cache/pip/wheels/5c/1c/94/b96c6b9a2eb858e26a675f86a908abfa53a593185b1c058823\n",
      "Successfully built fim\n",
      "Installing collected packages: fim\n",
      "Successfully installed fim-6.27\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pysbrl in /mnt/workspace/.local/lib/python3.5/site-packages (0.4.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package for scalable bayesian rule lists\n",
    "!pip3 install --user 'fim'\n",
    "!pip3 install --user 'pysbrl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementary\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import matplotlib\n",
    "import implicit\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For elementary data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For scalable bayesian rule lists\n",
    "import pysbrl\n",
    "\n",
    "# Import dataframe and cast names, datatypes and NaNs\n",
    "from names import column_names, labels\n",
    "basepath = \"/mnt/datasets/anomaly/\"\n",
    "dataDF = pd.read_csv(basepath + 'data.csv', delimiter=\";\", header=None, names=column_names)\n",
    "pure_dataDF = dataDF.drop(labels, axis=1)\n",
    "anomaliesDF = dataDF.filter(labels, axis=1) \n",
    "\n",
    "anomaliesDF_with_zerNA = anomaliesDF.fillna(0) # Fill NaNs with 0s, considering them as \"not an anomaly\"\n",
    "anomaliesDF_with_negNA = anomaliesDF.fillna(-1) # Fill NaNs with -1 considering them as a separate class for the classifier.\n",
    "pure_dataDF_with_negNA = pure_dataDF.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyttige artikler om stratified shuffle split\n",
    "* [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)\n",
    "* [Visualizing cross-validation behavior in scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)\n",
    "* [User guide: cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove data corresponding to one NaN column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_temp.shape: (287031, 35) \t X.shape: (262520, 35)\n"
     ]
    }
   ],
   "source": [
    "def create_binary_classification(puredataDF, anomaliesDF, label):\n",
    "    y = anomaliesDF[label]\n",
    "    indices_nan_labels = list(y.index[y.isnull()])\n",
    "    \n",
    "    X_mod = puredataDF.drop(indices_nan_labels, axis=0)\n",
    "    y_mod = y.drop(indices_nan_labels)\n",
    "    \n",
    "    X_mod = X_mod.reset_index().drop('index', axis=1)\n",
    "    y_mod = y_mod.reset_index().drop('index', axis=1)\n",
    "    return X_mod, y_mod\n",
    "\n",
    "# TEST ------------------------------------------------------\n",
    "X_temp = pure_dataDF_with_negNA.drop('Date',axis=1)\n",
    "X, y = create_binary_classification(X_temp, anomaliesDF, 'Check1')\n",
    "\n",
    "print('X_temp.shape:', X_temp.shape, '\\t', 'X.shape:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified-shuffle-split function\n",
    "\n",
    "This function will split the a given dataframe X, and corresponding label-series y (only one column), into train, validation and test sets such that the distribution of the different labels is retained in the different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# This function splits the dataset into 0.6 train, 0.2 val and 0.2 test sets ONLY SINGLE LABEL\n",
    "def train_val_test_split(X, y, seed):\n",
    "    # This generator splits the OG dataset into train and test sets\n",
    "    sss_train_test = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.2, \n",
    "                                   train_size = 0.8, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    # This generator splits the newly created train-set into train and validate sets\n",
    "    sss_train_val = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.25, \n",
    "                                   train_size = 0.75, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    for train_index, test_index in sss_train_test.split(X,y):\n",
    "        X_temp = X.loc[train_index, :]\n",
    "        y_temp = y.loc[train_index, :]\n",
    "        X_test = X.loc[test_index, :]\n",
    "        y_test = y.loc[test_index, :]\n",
    "\n",
    "    for train_index, test_index in sss_train_val.split(X_temp,y_temp):\n",
    "        X_train = X_temp.loc[train_index, :]\n",
    "        y_train = y_temp.loc[train_index, :]\n",
    "        X_val = X_temp.loc[test_index, :]\n",
    "        y_val = y_temp.loc[test_index, :]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# TEST ---------------------------------------------------------------------------------------\n",
    "seed = 42\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y, seed)\n",
    "\n",
    "print('####### Y TRAIN #######\\n', y_train.describe())\n",
    "print('\\n######## Y VAL ########\\n', y_val.describe())\n",
    "print('\\n####### Y TEST ########\\n', y_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable Bayesian Rule Lists\n",
    "### [github repo](https://github.com/myaooo/pysbrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical2pysbrl_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-41d0199f9eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save dataframes to the format the SBRL library requires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m categorical2pysbrl_data(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_train_mod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_train_mod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'X.out'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'categorical2pysbrl_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Save dataframes to the format the SBRL library requires\n",
    "categorical2pysbrl_data(\n",
    "    X_train_mod,\n",
    "    y_train_mod,\n",
    "    'X.out',\n",
    "    'y.label',\n",
    "    method='eclat',\n",
    "    supp=0.05,\n",
    "    zmin=1,\n",
    "    zmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SBRL Library from https://github.com/myaooo/pysbrl\n",
    "rule_ids, outputs, rule_strings = pysbrl.train_sbrl(\"data/ttt_train.out\", \n",
    "                                                    \"data/ttt_train.label\", \n",
    "                                                    20.0, \n",
    "                                                    eta=2.0, \n",
    "                                                    max_iters=2000, \n",
    "                                                    nchain=10, \n",
    "                                                    alphas=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
