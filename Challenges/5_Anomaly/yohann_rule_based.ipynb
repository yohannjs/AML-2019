{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook of task](https://github.com/DistributedSystemsGroup/Algorithmic-Machine-Learning/blob/master/Challenges/Anomaly_Detection/anomaly_detection_challenge.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a8/66fbb303236eb7e4caa63096814aa2675073f20aee95104920636af84a7e/fim-6.27.tar.gz (343kB)\n",
      "\u001b[K    100% |################################| 348kB 1.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: fim\n",
      "  Running setup.py bdist_wheel for fim ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /mnt/workspace/.cache/pip/wheels/5c/1c/94/b96c6b9a2eb858e26a675f86a908abfa53a593185b1c058823\n",
      "Successfully built fim\n",
      "Installing collected packages: fim\n",
      "Successfully installed fim-6.27\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pysbrl in /mnt/workspace/.local/lib/python3.5/site-packages (0.4.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package for scalable bayesian rule lists\n",
    "!pip3 install --user 'fim'\n",
    "!pip3 install --user 'pysbrl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementary\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import matplotlib\n",
    "import implicit\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For elementary data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For scalable bayesian rule lists\n",
    "import pysbrl\n",
    "\n",
    "# Import dataframe and cast names\n",
    "from names import column_names, labels\n",
    "basepath = \"/mnt/datasets/anomaly/\"\n",
    "dataDF = pd.read_csv(basepath + 'data.csv', delimiter=\";\", header=None, names=column_names)\n",
    "pure_dataDF = dataDF.drop(labels, axis=1)\n",
    "anomaliesDF = dataDF.filter(labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyttige artikler om stratified shuffle split\n",
    "* [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)\n",
    "* [Visualizing cross-validation behavior in scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)\n",
    "* [User guide: cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary error handling in dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nan values   : False\n",
      "All values finite: True\n"
     ]
    }
   ],
   "source": [
    "anomaliesDF_with_zerNA = anomaliesDF.fillna(0) # Fill NaNs with 0s, considering them as \"not an anomaly\"\n",
    "anomaliesDF_with_negNA = anomaliesDF.fillna(-1) # Fill NaNs with -1 considering them as a separate class for the classifier.\n",
    "pure_dataDF_with_negNA = pure_dataDF.fillna(-1)\n",
    "\n",
    "X_temp = pure_dataDF_with_negNA.drop('Date', axis=1)\n",
    "print('Any nan values   :', X_temp.isnull().any().any())\n",
    "print('All values finite:', np.isfinite(np.array(X_temp)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal\n",
    "X_temp.drop(['CleanupOOMDumps', 'PreprocessorRestarts', 'DaemonRestarts'], axis=1, inplace=True)\n",
    "\n",
    "# Direct recasting\n",
    "direct_recast = ['Dumps', 'CompositeOOMDums', 'DeltaSize', 'MergeErrors', 'BlockingPhaseSec', \n",
    "                 'LargestTableSize', 'LargestPartitionSize', 'DiagnosisFiles', 'DiagnosisFilesSize', \n",
    "                 'LogSegmentChange']\n",
    "for column in direct_recast:\n",
    "    X_temp[column] = X_temp[column].astype(np.int64, errors='ignore')\n",
    "\n",
    "#Format recasting\n",
    "format_recast = ['CPU', 'PhysMEM', 'InstanceMEM', 'TablesAllocation', 'IndexServerAllocationLimit', \n",
    "                    'Disk']\n",
    "for column in format_recast:\n",
    "    X_temp[column] = 100*X_temp[column]\n",
    "    X_temp[column] = X_temp[column].astype(np.int64, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SessionNumber                            int64\n",
      "SystemID                                 int64\n",
      "HighPriorityAlerts                       int64\n",
      "Dumps                                    int64\n",
      "CompositeOOMDums                         int64\n",
      "IndexServerRestarts                      int64\n",
      "NameServerRestarts                       int64\n",
      "XSEngineRestarts                         int64\n",
      "StatisticsServerRestarts                 int64\n",
      "CPU                                      int64\n",
      "PhysMEM                                  int64\n",
      "InstanceMEM                              int64\n",
      "TablesAllocation                         int64\n",
      "IndexServerAllocationLimit               int64\n",
      "ColumnUnloads                            int64\n",
      "DeltaSize                                int64\n",
      "MergeErrors                              int64\n",
      "BlockingPhaseSec                         int64\n",
      "Disk                                     int64\n",
      "LargestTableSize                         int64\n",
      "LargestPartitionSize                     int64\n",
      "DiagnosisFiles                           int64\n",
      "DiagnosisFilesSize                       int64\n",
      "DaysWithSuccessfulDataBackups            int64\n",
      "DaysWithSuccessfulLogBackups             int64\n",
      "DaysWithFailedDataBackups                int64\n",
      "DaysWithFailedfulLogBackups              int64\n",
      "MinDailyNumberOfSuccessfulDataBackups    int64\n",
      "MinDailyNumberOfSuccessfulLogBackups     int64\n",
      "MaxDailyNumberOfFailedDataBackups        int64\n",
      "MaxDailyNumberOfFailedLogBackups         int64\n",
      "LogSegmentChange                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_temp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove data corresponding to one NaN column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_temp.shape: (287031, 32) \t X.shape: (262520, 32)\n"
     ]
    }
   ],
   "source": [
    "def create_binary_classification(puredataDF, anomaliesDF, label):\n",
    "    y = anomaliesDF[label]\n",
    "    indices_nan_labels = list(y.index[y.isnull()])\n",
    "    \n",
    "    X_mod = puredataDF.drop(indices_nan_labels, axis=0)\n",
    "    y_mod = y.drop(indices_nan_labels)\n",
    "    y_mod = y_mod.astype(np.int64, errors='raise')\n",
    "    \n",
    "    X_mod = X_mod.reset_index().drop('index', axis=1)\n",
    "    y_mod = y_mod.reset_index().drop('index', axis=1)\n",
    "    return X_mod, y_mod\n",
    "\n",
    "X, y = create_binary_classification(X_temp, anomaliesDF, 'Check1')\n",
    "\n",
    "print('X_temp.shape:', X_temp.shape, '\\t', 'X.shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Check1    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified-shuffle-split function\n",
    "\n",
    "This function will split the a given dataframe X, and corresponding label-series y (only one column), into train, validation and test sets such that the distribution of the different labels is retained in the different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# This function splits the dataset into 0.6 train, 0.2 val and 0.2 test sets ONLY SINGLE LABEL\n",
    "def train_val_test_split(X, y, seed):\n",
    "    # This generator splits the OG dataset into train and test sets\n",
    "    sss_train_test = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.2, \n",
    "                                   train_size = 0.8, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    # This generator splits the newly created train-set into train and validate sets\n",
    "    sss_train_val = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.25, \n",
    "                                   train_size = 0.75, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    for train_index, test_index in sss_train_test.split(X,y):\n",
    "        X_temp = X.iloc[train_index, :]\n",
    "        y_temp = y.iloc[train_index, :]\n",
    "        X_test = X.iloc[test_index, :]\n",
    "        y_test = y.iloc[test_index, :]\n",
    "\n",
    "    for train_index, test_index in sss_train_val.split(X_temp,y_temp):\n",
    "        X_train = X_temp.iloc[train_index, :]\n",
    "        y_train = y_temp.iloc[train_index, :]\n",
    "        X_val = X_temp.iloc[test_index, :]\n",
    "        y_val = y_temp.iloc[test_index, :]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# TEST ---------------------------------------------------------------------------------------\n",
    "seed = 42\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y, seed)\n",
    "\n",
    "#print('####### Y TRAIN #######\\n', y_train.describe())\n",
    "#print('\\n######## Y VAL ########\\n', y_val.describe())\n",
    "#print('\\n####### Y TEST ########\\n', y_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable Bayesian Rule Lists\n",
    "### [github repo](https://github.com/myaooo/pysbrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 33 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-9d5edc6b63c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mx_by_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mx_by_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 33 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "def categorical2transactions(x):\n",
    "    # type: (np.ndarray) -> List\n",
    "    \"\"\"\n",
    "    Convert a 2D int array into a transaction list:\n",
    "        [\n",
    "            ['x0=1', 'x1=0', ...],\n",
    "            ...\n",
    "        ]\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 2\n",
    "\n",
    "    transactions = []\n",
    "    for entry in x:\n",
    "        transactions.append(['x%d=%d' % (i, val) for i, val in enumerate(entry)])\n",
    "\n",
    "    return transactions\n",
    "\n",
    "X_train = X_train.reset_index().drop('index', axis=1)\n",
    "y_train = y_train.reset_index().drop('index', axis=1)\n",
    "\n",
    "_X = np.array(X_train)\n",
    "_y = np.array(y_train)\n",
    "\n",
    "x = _X.astype(np.int, casting='safe')\n",
    "y = y_train.astype(np.int, casting='safe')\n",
    "\n",
    "labels = np.unique(y)\n",
    "labels = np.arange(np.max(labels) + 1)\n",
    "\n",
    "x_by_labels = []\n",
    "label = 0\n",
    "print(x[y == label])\n",
    "x_by_labels.append(x[y == label])\n",
    "\n",
    "\n",
    "# transactions_by_labels = [categorical2transactions(_x) for _x in x_by_labels]\n",
    "\n",
    "'''X_train = X_train.reset_index().drop('index', axis=1)\n",
    "y_train = y_train.reset_index().drop('index', axis=1)\n",
    "print(X_train[:5])\n",
    "print(y_train[:5])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "%d format: a number is required, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5a4e9195db48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0msupp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     \u001b[0mzmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                     zmax=3)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pysbrl/utils.py\u001b[0m in \u001b[0;36mcategorical2pysbrl_data\u001b[0;34m(x, y, data_filename, label_filename, method, supp, zmin, zmax)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx_by_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtransactions_by_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcategorical2transactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_by_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mitemsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransactions2freqitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions_by_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitemset2feature_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitemset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemsets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pysbrl/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx_by_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtransactions_by_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcategorical2transactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_by_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mitemsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransactions2freqitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions_by_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitemset2feature_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitemset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemsets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pysbrl/utils.py\u001b[0m in \u001b[0;36mcategorical2transactions\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mtransactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mtransactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x%d=%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pysbrl/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mtransactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mtransactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x%d=%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: %d format: a number is required, not str"
     ]
    }
   ],
   "source": [
    "# Save dataframes to the format the SBRL library requires\n",
    "pysbrl.utils.categorical2pysbrl_data(X_train,\n",
    "                                    y_train,\n",
    "                                    'X.out',\n",
    "                                    'y.label',\n",
    "                                    method='eclat',\n",
    "                                    supp=0.05,\n",
    "                                    zmin=1,\n",
    "                                    zmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SBRL Library from https://github.com/myaooo/pysbrl\n",
    "rule_ids, outputs, rule_strings = pysbrl.train_sbrl(\"data/ttt_train.out\", \n",
    "                                                    \"data/ttt_train.label\", \n",
    "                                                    20.0, \n",
    "                                                    eta=2.0, \n",
    "                                                    max_iters=2000, \n",
    "                                                    nchain=10, \n",
    "                                                    alphas=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
