{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook of task](https://github.com/DistributedSystemsGroup/Algorithmic-Machine-Learning/blob/master/Challenges/Anomaly_Detection/anomaly_detection_challenge.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a8/66fbb303236eb7e4caa63096814aa2675073f20aee95104920636af84a7e/fim-6.27.tar.gz (343kB)\n",
      "\u001b[K    100% |################################| 348kB 1.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: fim\n",
      "  Running setup.py bdist_wheel for fim ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /mnt/workspace/.cache/pip/wheels/5c/1c/94/b96c6b9a2eb858e26a675f86a908abfa53a593185b1c058823\n",
      "Successfully built fim\n",
      "Installing collected packages: fim\n",
      "Successfully installed fim-6.27\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pysbrl in /mnt/workspace/.local/lib/python3.5/site-packages (0.4.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package for scalable bayesian rule lists\n",
    "!pip3 install --user 'fim'\n",
    "!pip3 install --user 'pysbrl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementary\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import matplotlib\n",
    "import implicit\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For elementary data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For scalable bayesian rule lists\n",
    "import pysbrl\n",
    "\n",
    "# Import dataframe and cast names, datatypes and NaNs\n",
    "from names import column_names, labels\n",
    "basepath = \"/mnt/datasets/anomaly/\"\n",
    "dataDF = pd.read_csv(basepath + 'data.csv', delimiter=\";\", header=None, names=column_names)\n",
    "pure_dataDF = dataDF.drop(labels, axis=1)\n",
    "anomaliesDF = dataDF.filter(labels, axis=1) \n",
    "\n",
    "anomaliesDF_with_zerNA = anomaliesDF.fillna(0) # Fill NaNs with 0s, considering them as \"not an anomaly\"\n",
    "anomaliesDF_with_negNA = anomaliesDF.fillna(-1) # Fill NaNs with -1 considering them as a separate class for the classifier.\n",
    "pure_dataDF_with_negNA = pure_dataDF.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24511\n"
     ]
    }
   ],
   "source": [
    "check1DF = anomaliesDF['Check1']\n",
    "indices_of_zero_elements = list(check1DF[check1DF == 0].index)\n",
    "indices_of_nan_elements = list(check1DF[check1DF.isna()].index)\n",
    "print(len(indices_of_nan_elements))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyttige artikler om stratified shuffle split\n",
    "* [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)\n",
    "* [Visualizing cross-validation behavior in scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)\n",
    "* [User guide: cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified-shuffle-split function\n",
    "\n",
    "This function will split the a given dataframe X, and corresponding label-series y (only one columns), into train, validation and test sets such that the distribution of the different labels is retained in the different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Y TRAIN #######\n",
      " count    137918.000000\n",
      "mean         -0.079127\n",
      "std           0.290658\n",
      "min          -1.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           1.000000\n",
      "Name: Check1, dtype: float64\n",
      "\n",
      "######## Y VAL ########\n",
      " count    45721.000000\n",
      "mean        -0.081779\n",
      "std          0.294571\n",
      "min         -1.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: Check1, dtype: float64\n",
      "\n",
      "####### Y TEST ########\n",
      " count    57407.000000\n",
      "mean        -0.079694\n",
      "std          0.291096\n",
      "min         -1.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: Check1, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/series.py:842: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = pure_dataDF_with_negNA\n",
    "y = anomaliesDF_with_negNA['Check1']\n",
    "seed = 42\n",
    "\n",
    "# This function splits the dataset into 0.6 train, 0.2 val and 0.2 test sets\n",
    "def train_val_test_split(X, y, seed):\n",
    "    # This generator splits the OG dataset into train and test sets\n",
    "    sss_train_test = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.2, \n",
    "                                   train_size = 0.8, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    # This generator splits the newly created train-set into train and validate sets\n",
    "    sss_train_val = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.25, \n",
    "                                   train_size = 0.75, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    for train_index, test_index in sss_train_test.split(X,y):\n",
    "        X_temp = X.loc[train_index, :]\n",
    "        y_temp = y[train_index]\n",
    "        X_test = X.loc[test_index, :]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "    for train_index, test_index in sss_train_val.split(X_temp,y_temp):\n",
    "        X_train = X_temp.loc[train_index, :]\n",
    "        y_train = y_temp[train_index]\n",
    "        X_val = X_temp.loc[test_index, :]\n",
    "        y_val = y_temp[test_index]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y, seed)\n",
    "\n",
    "print('####### Y TRAIN #######\\n', y_train.describe())\n",
    "print('\\n######## Y VAL ########\\n', y_val.describe())\n",
    "print('\\n####### Y TEST ########\\n', y_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-made train-val-test-split-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-3-1cc464ab153d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1cc464ab153d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def train_val_test_split(train_size=0.6, val_size=0.2, with_nan=False, check, label_dataframe=anomaliesDF):\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def train_val_test_split(train_size=0.6, val_size=0.2, with_nan=False, check, label=anomaliesDF, pure_data):\n",
    "    test_size = 1 - train_size - test_size\n",
    "    if check == 'all':\n",
    "        # perform split for all categories\n",
    "        pass\n",
    "    else:\n",
    "        check_series = label_dataframe[check]\n",
    "        indices_of_zero_elements = list(check_series[check_series == 0].index)\n",
    "        indices_of_one_elements = list(check_series[check_series == 1].index)\n",
    "        \n",
    "        if with_nan == True:\n",
    "            indices_of_nan_elements = list(check_series[check_series.isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes to the format the SBRL library requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SBRL Library from https://github.com/myaooo/pysbrl\n",
    "rule_ids, outputs, rule_strings = pysbrl.train_sbrl(\"data/ttt_train.out\", \n",
    "                                                    \"data/ttt_train.label\", \n",
    "                                                    20.0, \n",
    "                                                    eta=2.0, \n",
    "                                                    max_iters=2000, \n",
    "                                                    nchain=10, \n",
    "                                                    alphas=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
