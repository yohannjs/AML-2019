{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook of task](https://github.com/DistributedSystemsGroup/Algorithmic-Machine-Learning/blob/master/Challenges/Anomaly_Detection/anomaly_detection_challenge.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a8/66fbb303236eb7e4caa63096814aa2675073f20aee95104920636af84a7e/fim-6.27.tar.gz (343kB)\n",
      "\u001b[K    100% |################################| 348kB 1.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: fim\n",
      "  Running setup.py bdist_wheel for fim ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /mnt/workspace/.cache/pip/wheels/5c/1c/94/b96c6b9a2eb858e26a675f86a908abfa53a593185b1c058823\n",
      "Successfully built fim\n",
      "Installing collected packages: fim\n",
      "Successfully installed fim-6.27\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pysbrl in /mnt/workspace/.local/lib/python3.5/site-packages (0.4.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package for scalable bayesian rule lists\n",
    "!pip3 install --user 'fim'\n",
    "!pip3 install --user 'pysbrl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementary\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import matplotlib\n",
    "import implicit\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For elementary data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For scalable bayesian rule lists\n",
    "import pysbrl\n",
    "\n",
    "# Import dataframe and cast names\n",
    "from names import column_names, labels\n",
    "basepath = \"/mnt/datasets/anomaly/\"\n",
    "dataDF = pd.read_csv(basepath + 'data.csv', delimiter=\";\", header=None, names=column_names)\n",
    "pure_dataDF = dataDF.drop(labels, axis=1)\n",
    "anomaliesDF = dataDF.filter(labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyttige artikler om stratified shuffle split\n",
    "* [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)\n",
    "* [Visualizing cross-validation behavior in scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)\n",
    "* [User guide: cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary error handling in dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nan values   : False\n",
      "All values finite: True\n"
     ]
    }
   ],
   "source": [
    "anomaliesDF_with_zerNA = anomaliesDF.fillna(0) # Fill NaNs with 0s, considering them as \"not an anomaly\"\n",
    "anomaliesDF_with_negNA = anomaliesDF.fillna(-1) # Fill NaNs with -1 considering them as a separate class for the classifier.\n",
    "pure_dataDF_with_negNA = pure_dataDF.fillna(-1)\n",
    "\n",
    "X_t = pure_dataDF_with_negNA.drop('Date', axis=1)\n",
    "print('Any nan values   :', X_t.isnull().any().any())\n",
    "print('All values finite:', np.isfinite(np.array(X_t)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal\n",
    "X_temp = X_t.drop(['CleanupOOMDumps', 'PreprocessorRestarts', 'DaemonRestarts'], axis=1)\n",
    "\n",
    "# Direct recasting\n",
    "direct_recast = ['Dumps', 'CompositeOOMDums', 'DeltaSize', 'MergeErrors', 'BlockingPhaseSec', \n",
    "                 'LargestTableSize', 'LargestPartitionSize', 'DiagnosisFiles', 'DiagnosisFilesSize', \n",
    "                 'LogSegmentChange']\n",
    "for column in direct_recast:\n",
    "    X_temp[column] = X_temp[column].astype(np.int64, errors='ignore')\n",
    "\n",
    "#Format recasting\n",
    "format_recast = ['CPU', 'PhysMEM', 'InstanceMEM', 'TablesAllocation', 'IndexServerAllocationLimit', \n",
    "                    'Disk']\n",
    "for column in format_recast:\n",
    "    X_temp[column] = 100*X_temp[column]\n",
    "    X_temp[column] = X_temp[column].astype(np.int64, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_temp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove data corresponding to one NaN column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_temp.shape: (287031, 32) \t X.shape: (262520, 32)\n"
     ]
    }
   ],
   "source": [
    "def create_binary_classification(puredataDF, anomaliesDF, label):\n",
    "    y = anomaliesDF[label]\n",
    "    indices_nan_labels = list(y.index[y.isnull()])\n",
    "    \n",
    "    X_mod = puredataDF.drop(indices_nan_labels, axis=0)\n",
    "    y_mod = y.drop(indices_nan_labels)\n",
    "    y_mod = y_mod.astype(np.int64, errors='raise')\n",
    "    \n",
    "    X_mod = X_mod.reset_index().drop('index', axis=1)\n",
    "    y_mod = y_mod.reset_index().drop('index', axis=1)\n",
    "    return X_mod, y_mod\n",
    "\n",
    "X, y = create_binary_classification(X_temp, anomaliesDF, 'Check1')\n",
    "\n",
    "print('X_temp.shape:', X_temp.shape, '\\t', 'X.shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Check1    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified-shuffle-split function\n",
    "\n",
    "This function will split the a given dataframe X, and corresponding label-series y (only one column), into train, validation and test sets such that the distribution of the different labels is retained in the different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# This function splits the dataset into 0.6 train, 0.2 val and 0.2 test sets ONLY SINGLE LABEL\n",
    "def train_val_test_split(X, y, seed):\n",
    "    # This generator splits the OG dataset into train and test sets\n",
    "    sss_train_test = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.2, \n",
    "                                   train_size = 0.8, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    # This generator splits the newly created train-set into train and validate sets\n",
    "    sss_train_val = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                   test_size = 0.25, \n",
    "                                   train_size = 0.75, \n",
    "                                   random_state = seed)\n",
    "\n",
    "    for train_index, test_index in sss_train_test.split(X,y):\n",
    "        X_temp = X.iloc[train_index, :]\n",
    "        y_temp = y.iloc[train_index, :]\n",
    "        X_test = X.iloc[test_index, :]\n",
    "        y_test = y.iloc[test_index, :]\n",
    "\n",
    "    for train_index, test_index in sss_train_val.split(X_temp,y_temp):\n",
    "        X_train = X_temp.iloc[train_index, :]\n",
    "        y_train = y_temp.iloc[train_index, :]\n",
    "        X_val = X_temp.iloc[test_index, :]\n",
    "        y_val = y_temp.iloc[test_index, :]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_temp, y_temp\n",
    "\n",
    "# TEST ---------------------------------------------------------------------------------------\n",
    "seed = 42\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_train_big, y_train_big = train_val_test_split(X, y, seed)\n",
    "\n",
    "#print('####### Y TRAIN #######\\n', y_train.describe())\n",
    "#print('\\n######## Y VAL ########\\n', y_val.describe())\n",
    "#print('\\n####### Y TEST ########\\n', y_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable Bayesian Rule Lists\n",
    "### [github repo](https://github.com/myaooo/pysbrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dataframe took 57.93 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# We block print becuase categorical2pysbrl_data prints out a lot of uninteresting data to stdout. \n",
    "\n",
    "# Save dataframes to the format the SBRL library requires\n",
    "def format_dataframe(X, y, file_X, file_y):\n",
    "    # Convert to numpy ndarray\n",
    "    _X = X.values\n",
    "    _y = y.values[:,0]\n",
    "    \n",
    "    name_X = file_X + '.out'\n",
    "    name_y = file_y + '.label'\n",
    "    \n",
    "    with HiddenPrints():\n",
    "        pysbrl.utils.categorical2pysbrl_data(_X,\n",
    "                                            _y,\n",
    "                                            name_X,\n",
    "                                            name_y,\n",
    "                                            method='eclat',\n",
    "                                            supp=0.05,\n",
    "                                            zmin=1,\n",
    "                                            zmax=3)\n",
    "\n",
    "t0 = time()\n",
    "format_dataframe(X_train_big, y_train_big, 'X_train_big', 'y_train_big')   \n",
    "t1 = time()\n",
    "print('Converting dataframe took %.2f seconds' % (t1 - t0))\n",
    "# print('We dont need to convert every time, only once.\\nLast time converting dataframe took 61.00 seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SBRL based model took 32.48 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Using SBRL Library from https://github.com/myaooo/pysbrl\n",
    "rule_ids, outputs, rule_strings = pysbrl.train_sbrl(\"X_train_big.out\", \n",
    "                                                    \"y_train_big.label\", \n",
    "                                                    20.0, \n",
    "                                                    eta=2.0, \n",
    "                                                    max_iters=2000) \n",
    "                                                    #nchain=10, \n",
    "                                                    #alphas=[1,1])\n",
    "\n",
    "print('Training the SBRL based model took %.2f seconds' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Rule | $P(Check1 = 0)$ | $P(Check1 = 1)$ |\n",
       "|:-----|:----------------|:----------------|\n",
       "| DiagnosisFilesSize=-1 | 0.99761 | 0.00239 |\n",
       "| CompositeOOMDums=0 and NameServerRestarts=0 and CPU=10000 | 0.02857 | 0.97143 |\n",
       "| HighPriorityAlerts=0 and Dumps=0 | 0.99982 | 0.00018 |\n",
       "| DaysWithSuccessfulLogBackups=8 and HighPriorityAlerts=1 and Dumps=0 | 0.99902 | 0.00098 |\n",
       "| ColumnUnloads=0 and DaysWithSuccessfulLogBackups=8 and HighPriorityAlerts=2 | 0.99815 | 0.00185 |\n",
       "| MinDailyNumberOfSuccessfulDataBackups=1 and CPU=10000 | 0.07143 | 0.92857 |\n",
       "| BlockingPhaseSec=3 and StatisticsServerRestarts=0 | 0.99670 | 0.00330 |\n",
       "| BlockingPhaseSec=2 | 0.99832 | 0.00168 |\n",
       "| HighPriorityAlerts=2 and NameServerRestarts=0 and StatisticsServerRestarts=0 | 0.99456 | 0.00544 |\n",
       "| HighPriorityAlerts=1 and NameServerRestarts=0 and XSEngineRestarts=0 | 0.99616 | 0.00384 |\n",
       "| MinDailyNumberOfSuccessfulLogBackups=1 and Dumps=0 and NameServerRestarts=0 | 0.96511 | 0.03489 |\n",
       "| SystemID=73 and DaysWithFailedfulLogBackups=0 and MaxDailyNumberOfFailedDataBackups=0 | 0.92206 | 0.07794 |\n",
       "| HighPriorityAlerts=3 and IndexServerRestarts=0 and StatisticsServerRestarts=0 | 0.99603 | 0.00397 |\n",
       "| ColumnUnloads=0 and DaysWithFailedfulLogBackups=0 and HighPriorityAlerts=4 | 0.99343 | 0.00657 |\n",
       "| ColumnUnloads=0 and HighPriorityAlerts=6 | 0.99031 | 0.00969 |\n",
       "| HighPriorityAlerts=4 and IndexServerRestarts=0 and XSEngineRestarts=0 | 0.99671 | 0.00329 |\n",
       "| HighPriorityAlerts=5 and XSEngineRestarts=0 | 0.99084 | 0.00916 |\n",
       "| DaysWithSuccessfulDataBackups=1 and DaysWithSuccessfulLogBackups=8 and StatisticsServerRestarts=0 | 0.91540 | 0.08460 |\n",
       "| Default | 0.97631 | 0.02369 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def translate_output_to_text(rule_ids, outputs, rule_strings, filename, column_names, label, verbose):\n",
    "    rules = [rule_strings[i] for i in rule_ids]\n",
    "    split_rules = [rule[1:-1].split(',') for rule in rules[:-1]] # LAST RULE IS ONLY 'default'\n",
    "    \n",
    "    rules_with_column_names = []\n",
    "    for num_rule in split_rules:\n",
    "        rule_with_column_names = []\n",
    "        for sub_rule in num_rule:\n",
    "            col_number = int(sub_rule.split('=')[0][1:])\n",
    "            col_name = column_names[col_number]\n",
    "            new_sub_rule = col_name + '=' + sub_rule.split('=')[1]\n",
    "            rule_with_column_names.append(new_sub_rule)\n",
    "        rules_with_column_names.append(rule_with_column_names)\n",
    "    \n",
    "    to_return = rules_with_column_names.copy()\n",
    "    \n",
    "    f = open(filename,'w+')\n",
    "    f.write('| Rule | $P(%s = 0)$ | $P(%s = 1)$ |\\n' % (label, label))\n",
    "    f.write('|:-----|:----------------|:----------------|\\n')\n",
    "    \n",
    "    separator = ' and '\n",
    "    for i in range(len(outputs[:-1])):\n",
    "        rule_to_write = separator.join(rules_with_column_names[i])\n",
    "        output = outputs[i]\n",
    "        string_to_write = '| ' + rule_to_write + ' | %.5f | %.5f |' % (output[0], output[1]) + '\\n'\n",
    "        f.write(string_to_write)\n",
    "        #print(string_to_write[:-1])\n",
    "    \n",
    "    default_prob = outputs[-1]\n",
    "    f.write('| Default | %.5f | %.5f |\\n' % (default_prob[0], default_prob[1]))\n",
    "    f.close()\n",
    "    \n",
    "    if verbose == True:\n",
    "        with open(filename, 'r') as fh:\n",
    "            content = fh.read()\n",
    "        display(Markdown(content))\n",
    "    \n",
    "    return to_return\n",
    "    \n",
    "rules = translate_output_to_text(rule_ids=rule_ids, \n",
    "                         outputs=outputs, \n",
    "                         rule_strings=rule_strings, \n",
    "                         filename='created_rules.md', \n",
    "                         column_names=X_train_big.columns,\n",
    "                         label=list(y_train_big.columns)[0],\n",
    "                         verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_row = X_train_big.iloc[0,:]\\n\\nexit = 0\\n#print(element)\\nfor el in X_test.iterrows():\\n    print((el[1]['SystemID']))\\n    exit += 1\\n    if exit == 3:\\n        break; \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test_row = X_train_big.iloc[0,:]\n",
    "\n",
    "exit = 0\n",
    "#print(element)\n",
    "for el in X_test.iterrows():\n",
    "    print((el[1]['SystemID']))\n",
    "    exit += 1\n",
    "    if exit == 3:\n",
    "        break; '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rule(formatted_rule, row_series):\n",
    "    pass_var = True\n",
    "    for sub_rule in formatted_rule:\n",
    "        if (row_series[sub_rule.split('=')[0]] != int(sub_rule.split('=')[1])):\n",
    "            pass_var = False\n",
    "            break\n",
    "    return pass_var\n",
    "\n",
    "\n",
    "test_rule = rules[0]\n",
    "test_row = X_train_big.iloc[0,:]\n",
    "i = check_rule(test_rule, test_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def predict_row(formatted_rule_list, outputs, row_series):\n",
    "    prediction = 7\n",
    "    for i in range(len(formatted_rule_list)):\n",
    "        if(check_rule(formatted_rule_list[i], row_series) == True):\n",
    "            prediction = int(np.round(outputs[i,1]))\n",
    "            break\n",
    "    if prediction == 7:\n",
    "        prediction = int(np.round(outputs[-1,1]))\n",
    "    return prediction\n",
    "\n",
    "print(predict_row(rules,outputs,test_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBRL_predict(formatted_rule_list, outputs, X_test, y_test):\n",
    "    y_pred = pd.Series(np.zeros(y_test.shape[0], dtype=int))\n",
    "    for index, row_series in X_test.iterrows():\n",
    "        y_pred.iloc[index] = predict_row(formatted_rule_list, outputs, row_series)\n",
    "    return y_pred\n",
    " \n",
    "y_pred = SBRL_predict(rules, outputs, X_test.reset_index(), y_test.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_np = y_pred.values\n",
    "print(y_pred_np[:3])\n",
    "y_test_np = y_test.values[:,0]\n",
    "print(y_test_np[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52504,)\n",
      "F1 Score of model = 100.00\n",
      "Accuracy in 1s = 4.28\n",
      "Accuracy in 0s = 99.99808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "print(y_pred.shape)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "f1 = f1_score(y_test, y_test, average='macro')\n",
    "print('F1 Score of model = %.2f' %(f1*100))\n",
    "print('Accuracy in 1s = %.2f' %(tp/(tp + fn)*100))\n",
    "print('Accuracy in 0s = %.5f' %(tn/(tn + fp)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformatting\n",
      "Training SBRL model\n",
      "Training the SBRL based model took 33.25 seconds\n",
      "Using model for predictions\n",
      "F1 Score of model = 100.00\n",
      "Accuracy in 1s = 4.28\n",
      "Accuracy in 0s = 99.99808\n"
     ]
    }
   ],
   "source": [
    "def full_pipeline_SBRL(X_train, y_train, X_test, y_test, verbose):\n",
    "    # REFORMATTING input_data ----------------------------------------------------------------\n",
    "    print('Reformatting')\n",
    "    format_dataframe(X_train, y_train, 'file_X', 'file_y')\n",
    "    \n",
    "    # TRAINING SBRL MODEL ---------------------------------------------------------------\n",
    "    print('Training SBRL model')\n",
    "    t2 = time()\n",
    "\n",
    "    # Using SBRL Library from https://github.com/myaooo/pysbrl\n",
    "    rule_ids, outputs, rule_strings = pysbrl.train_sbrl('file_X.out', \n",
    "                                                        'file_y.label', \n",
    "                                                        20.0, \n",
    "                                                        eta=2.0, \n",
    "                                                        max_iters=2000) \n",
    "                                                        #nchain=10, \n",
    "                                                        #alphas=[1,1])\n",
    "    \n",
    "    t3 = time()\n",
    "    print('Training the SBRL based model took %.2f seconds' % (t3 - t2))\n",
    "    \n",
    "    # PRINTING DATA IN NICE FORMAT -------------------------------------------------------\n",
    "    formatted_rule_list = translate_output_to_text(rule_ids=rule_ids, \n",
    "                                                     outputs=outputs, \n",
    "                                                     rule_strings=rule_strings, \n",
    "                                                     filename='function_rule_file.md', \n",
    "                                                     column_names=X_train.columns,\n",
    "                                                     label=list(y_train.columns)[0],\n",
    "                                                     verbose=verbose)\n",
    "    \n",
    "    # TESTING MODEL ----------------------------------------------------------------------\n",
    "    test_data = X_test.reset_index().drop('index', axis=1)\n",
    "    test_labels = y_test.reset_index().drop('index', axis=1)\n",
    "    print('Using model for predictions')\n",
    "    y_pred = SBRL_predict(formatted_rule_list=formatted_rule_list, \n",
    "                          outputs=outputs, \n",
    "                          X_test=test_data, \n",
    "                          y_test=test_labels)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    f1 = f1_score(y_test, y_test, average='macro')\n",
    "    print('F1 Score of model = %.2f' %(f1*100))\n",
    "    print('Accuracy in 1s = %.2f' %(tp/(tp + fn)*100))\n",
    "    print('Accuracy in 0s = %.5f' %(tn/(tn + fp)*100))\n",
    "\n",
    "full_pipeline_SBRL(X_train_big, y_train_big, X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
