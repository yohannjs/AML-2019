{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook of task](https://github.com/DistributedSystemsGroup/Algorithmic-Machine-Learning/blob/master/Challenges/Plankton/plankton_challenge.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Plankton based on features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlens\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/f7/c04bda423ac93ddb54bc4c3a21c79c9a24bc83844efc30dc4c11c289e894/mlens-0.2.3-py2.py3-none-any.whl (227kB)\n",
      "\u001b[K    100% |################################| 235kB 1.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.5/dist-packages (from mlens) (1.14.5)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.5/dist-packages (from mlens) (1.1.0)\n",
      "Installing collected packages: mlens\n",
      "Successfully installed mlens-0.2.3\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user 'mlens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# For configuration and jupiter\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import matplotlib\n",
    "import implicit\n",
    "import warnings\n",
    "# For data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# For prediction\n",
    "from tqdm import tqdm\n",
    "\n",
    "basepath = \"/mnt/datasets/plankton/flowcam/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nativeDF = pd.read_csv(basepath + 'features_native.csv.gz')\n",
    "labelsDF = pd.read_csv(basepath + 'meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nativeDF.isnull().sum().sort_values(ascending=False)[:10])\n",
    "#print(skimagDF.isnull().sum().sort_values(ascending=False)[:6])\n",
    "\n",
    "native_nan_cols = ['perimareaexc', 'feretareaexc', 'cdexc', 'skeleton_area',\n",
    "                   'nb1_area', 'symetrieh_area', 'symetriev_area', 'convarea_area',\n",
    "                  'nb2_area', 'nb3_area', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for col_name in native_nan_cols:\n",
    "    nativeDF[col_name] = nativeDF[col_name].fillna(0)\n",
    "\n",
    "labelsDF['objid'] = labelsDF['objid'].astype(np.int64, errors='ignore')\n",
    "labelsDF['level1'] = labelsDF['level1'].fillna('No_level1_name')\n",
    "labelsDF['level2'] = labelsDF['level2'].fillna('No_level2_name')\n",
    "\n",
    "print(nativeDF.isnull().sum().any())\n",
    "print(labelsDF.isnull().sum().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labelsDF['level2'] \n",
    "X = nativeDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide train data into train and validation sets\n",
    "\n",
    "seed = 42\n",
    "test_size = 0.20\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = test_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA performs best with a normalized feature set \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "scX_train = sc.fit_transform(X_train)  \n",
    "scX_test = sc.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 65 attributes in NativeDF\n",
    "# 30 elements: 99,0%, 10 elements 83,4%, 20 elements: 96,1%\n",
    "\n",
    "pca = PCA(.99)  \n",
    "pcaX_train = pca.fit_transform(scX_train)  \n",
    "pcaX_test = pca.transform(scX_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>F1 Macro Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>52.920652</td>\n",
       "      <td>10.166362</td>\n",
       "      <td>0.108554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>74.951767</td>\n",
       "      <td>8.651353</td>\n",
       "      <td>0.355398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>81.562744</td>\n",
       "      <td>1.827556</td>\n",
       "      <td>0.453720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>48.312877</td>\n",
       "      <td>3.286494</td>\n",
       "      <td>0.229631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>36.055581</td>\n",
       "      <td>22.061722</td>\n",
       "      <td>0.219377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier   Accuracy   Log Loss  F1 Macro Score\n",
       "0    KNeighborsClassifier  52.920652  10.166362        0.108554\n",
       "0  DecisionTreeClassifier  74.951767   8.651353        0.355398\n",
       "0  RandomForestClassifier  81.562744   1.827556        0.453720\n",
       "0      AdaBoostClassifier  48.312877   3.286494        0.229631\n",
       "0           MLPClassifier  36.055581  22.061722        0.219377"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    MLPClassifier(alpha=1)\n",
    "    ]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\", \"F1 Macro Score\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    \n",
    "    f1 = f1_score(y_test, train_predictions, average='macro', labels=np.unique(train_predictions))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll, f1]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 Score:  0.5051115100965339\n"
     ]
    }
   ],
   "source": [
    "# without PCA, RandomForestClassifer is best and KNeighbours and MLP is awful. With PCA, MLP and KNeighbours perform similar to DecisionTree and RandomForest\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy')\n",
    "model.fit(X_train, y_train)\n",
    "model_predictions = model.predict(X_test)\n",
    "model_f1 = f1_score(y_test, model_predictions, average='macro', labels=np.unique(model_predictions))\n",
    "print(\"Final F1 Score: \", model_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fbc64ca8270, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fbc64ca8270, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    340             raise RuntimeError('Event loop is running.')\n    341         self._set_coroutine_wrapper(self._debug)\n    342         self._thread_id = threading.get_ident()\n    343         try:\n    344             while True:\n--> 345                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    346                 if self._stopping:\n    347                     break\n    348         finally:\n    349             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1307                         logger.warning('Executing %s took %.3f seconds',\n   1308                                        _format_handle(handle), dt)\n   1309                 finally:\n   1310                     self._current_handle = None\n   1311             else:\n-> 1312                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(14, 1)>>\n   1313         handle = None  # Needed to break cycles when an exception occurs.\n   1314 \n   1315     def _set_coroutine_wrapper(self, enabled):\n   1316         try:\n\n...........................................................................\n/usr/lib/python3.5/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(14, 1)>)\n    120             self._callback = None\n    121             self._args = None\n    122 \n    123     def _run(self):\n    124         try:\n--> 125             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (14, 1)\n    126         except Exception as exc:\n    127             cb = _format_callback_source(self._callback, self._args)\n    128             msg = 'Exception in callback {}'.format(cb)\n    129             context = {\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=14, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 30, 18, 14, 36, 20273, tzinfo=tzlocal()), 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'session': '96576236-0499-4cf8-befb-bb24bd7109e0', 'username': '', 'version': '5.2'}, 'metadata': {'cellId': '02725818-9b2a-4fa3-81c8-d6c31092c1a1', 'deletedCells': ['7d83f08b-76d3-4762-9a57-3bc71993da33']}, 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'96576236-0499-4cf8-befb-bb24bd7109e0']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 30, 18, 14, 36, 20273, tzinfo=tzlocal()), 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'session': '96576236-0499-4cf8-befb-bb24bd7109e0', 'username': '', 'version': '5.2'}, 'metadata': {'cellId': '02725818-9b2a-4fa3-81c8-d6c31092c1a1', 'deletedCells': ['7d83f08b-76d3-4762-9a57-3bc71993da33']}, 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'96576236-0499-4cf8-befb-bb24bd7109e0'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 30, 18, 14, 36, 20273, tzinfo=tzlocal()), 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'session': '96576236-0499-4cf8-befb-bb24bd7109e0', 'username': '', 'version': '5.2'}, 'metadata': {'cellId': '02725818-9b2a-4fa3-81c8-d6c31092c1a1', 'deletedCells': ['7d83f08b-76d3-4762-9a57-3bc71993da33']}, 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-22-6f2e6ece3240>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fbbd7d46e80, executi...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fbbe151ca50, file \"<ipython-input-22-6f2e6ece3240>\", line 24>\n        result = <ExecutionResult object at 7fbbd7d46e80, executi...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fbbe151ca50, file \"<ipython-input-22-6f2e6ece3240>\", line 24>, result=<ExecutionResult object at 7fbbd7d46e80, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fbbe151ca50, file \"<ipython-input-22-6f2e6ece3240>\", line 24>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'In': ['', '# stacking \\nfrom mlens.ensemble import Subsemble', 'get_ipython().system(\"pip3 install -user \\'mlens\\'\")', 'get_ipython().system(\"pip3 install -user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens\\'\")', '# stacking \\nfrom mlens.ensemble import Subsemble', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'get_ipython().run_line_magic(\\'matplotlib\\', \\'inli...qdm\\n\\nbasepath = \"/mnt/datasets/plankton/flowcam/\"', \"nativeDF = pd.read_csv(basepath + 'features_nati...z')\\nlabelsDF = pd.read_csv(basepath + 'meta.csv')\", \"#print(nativeDF.isnull().sum().sort_values(ascen...rea',\\n                  'nb2_area', 'nb3_area', ]\", 'for col_name in native_nan_cols:\\n    nativeDF[co...sum().any())\\nprint(labelsDF.isnull().sum().any())', \"y = labelsDF['level2'] \\nX = nativeDF\", 'from sklearn.model_selection import train_test_s...X, y, test_size = test_size, random_state = seed)', 'from sklearn.metrics import accuracy_score, log_...og_cols)\\n    log = log.append(log_entry)\\n    \\nlog', \"def f1(y_test, pred):\\n    return f1_score(y_test, pred, average='macro', labels=np.unique(pred))\", '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', \"from mlens.metrics import make_scorer\\n\\nf1 = make...t, pred, average='macro', labels=np.unique(pred))\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {14:                Classifier   Accuracy   Log Loss ...PClassifier  36.055581  22.061722        0.219377}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Subsemble': <class 'mlens.ensemble.subsemble.Subsemble'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'In': ['', '# stacking \\nfrom mlens.ensemble import Subsemble', 'get_ipython().system(\"pip3 install -user \\'mlens\\'\")', 'get_ipython().system(\"pip3 install -user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens\\'\")', '# stacking \\nfrom mlens.ensemble import Subsemble', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'get_ipython().run_line_magic(\\'matplotlib\\', \\'inli...qdm\\n\\nbasepath = \"/mnt/datasets/plankton/flowcam/\"', \"nativeDF = pd.read_csv(basepath + 'features_nati...z')\\nlabelsDF = pd.read_csv(basepath + 'meta.csv')\", \"#print(nativeDF.isnull().sum().sort_values(ascen...rea',\\n                  'nb2_area', 'nb3_area', ]\", 'for col_name in native_nan_cols:\\n    nativeDF[co...sum().any())\\nprint(labelsDF.isnull().sum().any())', \"y = labelsDF['level2'] \\nX = nativeDF\", 'from sklearn.model_selection import train_test_s...X, y, test_size = test_size, random_state = seed)', 'from sklearn.metrics import accuracy_score, log_...og_cols)\\n    log = log.append(log_entry)\\n    \\nlog', \"def f1(y_test, pred):\\n    return f1_score(y_test, pred, average='macro', labels=np.unique(pred))\", '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', \"from mlens.metrics import make_scorer\\n\\nf1 = make...t, pred, average='macro', labels=np.unique(pred))\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {14:                Classifier   Accuracy   Log Loss ...PClassifier  36.055581  22.061722        0.219377}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Subsemble': <class 'mlens.ensemble.subsemble.Subsemble'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/mnt/workspace/AML-2019/Challenges/4_Plankton/<ipython-input-22-6f2e6ece3240> in <module>()\n     19 \n     20 # Build the first layer\n     21 ensemble.add([rf, kn, dt, mlpc])\n     22 # Attach the final meta estimator\n     23 ensemble.add_meta(lr)\n---> 24 ensemble.fit(X_train, y_train)\n     25 e_preds = ensemble.predict(X_test)\n     26 \n     27 e_f1 = f1_score(y_test, e_preds, average='macro', labels=np.unique(e_preds))\n     28 print(\"Stacked F1 Score: \", e_f1)\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=Subsemble(array_check=None, backend=None, folds=...oceros danicus']),\n     shuffle=False, verbose=2), X=             objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], y=133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object, **kwargs={})\n    509             return self\n    510 \n    511         if self.model_selection:\n    512             self._id_train.fit(X)\n    513 \n--> 514         out = self._backend.fit(X, y, **kwargs)\n        out = undefined\n        self._backend.fit = <bound method Sequential.fit of Sequential(backe...nsformers=[])],\n   verbose=1)],\n      verbose=2)>\n        X =              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns]\n        y = 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object\n        kwargs = {}\n    515         if out is not self._backend:\n    516             # fit_transform\n    517             return out\n    518         else:\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), X=             objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], y=133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object, **kwargs={})\n    153 \n    154         f, t0 = print_job(self, \"Fitting\")\n    155 \n    156         with ParallelProcessing(self.backend, self.n_jobs,\n    157                                 max(self.verbose - 4, 0)) as manager:\n--> 158             out = manager.stack(self, 'fit', X, y, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        X =              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns]\n        y = 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object\n        kwargs = {}\n    159 \n    160         if self.verbose:\n    161             print_time(t0, \"{:<35}\".format(\"Fit complete\"), file=f)\n    162 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), job='fit', X=             objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], y=133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object, path=None, return_preds=False, warm_start=False, split=True, **kwargs={})\n    668             Prediction array(s).\n    669         \"\"\"\n    670         out = self.initialize(\n    671             job=job, X=X, y=y, path=path, warm_start=warm_start,\n    672             return_preds=return_preds, split=split, stack=True)\n--> 673         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        out = {}\n        kwargs = {}\n    674 \n    675     def process(self, caller, out, **kwargs):\n    676         \"\"\"Process job.\n    677 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), out=None, **kwargs={})\n    713                       backend=self.backend) as parallel:\n    714 \n    715             for task in caller:\n    716                 self.job.clear()\n    717 \n--> 718                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    719 \n    720                 if task.name in return_names:\n    721                     out.append(self.get_preds(dtype=_dtype(task)))\n    722 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), parallel=Parallel(n_jobs=-1), **kwargs={})\n    734         task.setup(self.job.predict_in, self.job.targets, self.job.job)\n    735 \n    736         if not task.__no_output__:\n    737             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    738 \n--> 739         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    740 \n    741         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    742             self._propagate_features(task)\n    743 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), args={'auxiliary': {'P': None, 'X':              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], 'y': 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object}, 'dir': [('kneighborsclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>), ('kneighborsclassifier.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('decisiontreeclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>), ('decisiontreeclassifier.0.0', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'X':              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], 'y': 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus'])), Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus'])), Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus'])), Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus']))]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Apr 30 18:15:58 2019\nPID: 541                                     Python 3.5.2: /usr/bin/python3\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('kneighborsclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>), ('kneighborsclassifier.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('decisiontreeclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>)])\n    131         transformers = self._load_preprocess(path)\n    132 \n    133         self._fit(transformers)\n    134 \n    135         if self.out_array is not None:\n--> 136             self._predict(transformers, self.scorer is not None)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n        self.scorer = make_scorer(f1_score, average=macro, labels=['An...llen' 'rods' 'silks'\n 'tempChaetoceros danicus'])\n    137 \n    138         o = IndexedEstimator(estimator=self.estimator,\n    139                              name=self.name_index,\n    140                              index=self.index,\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=True)\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n    204         assign_predictions(self.out_array, predictions,\n--> 205                            self.out_index, self.output_columns, n)\n        self.out_index = [(0, 9745), (97444, 107189)]\n        self.output_columns = 0\n        n = 194888\n    206 \n    207         # Score predictions if applicable\n    208         if score_preds:\n    209             self.score_ = score_predictions(\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/_base_functions.py in assign_predictions(pred=array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), p=array(['detritus', 'feces', 'badfocus (artefact)...s',\n       'detritus', 'detritus'], dtype=object), tei=[(0, 9745), (97444, 107189)], col=0, n=194888)\n    208                 idx = slice(tei[0] - r, tei[1] - r)\n    209         else:\n    210             idx = slice(tei[0] - r, tei[1] - r)\n    211 \n    212         if len(p.shape) == 1:\n--> 213             pred[idx, col] = p\n        pred = array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n        idx = array([     0,      1,      2, ..., 107186, 107187, 107188])\n        col = 0\n        p = array(['detritus', 'feces', 'badfocus (artefact)...s',\n       'detritus', 'detritus'], dtype=object)\n    214         else:\n    215             pred[(idx, slice(col, col + p.shape[1]))] = p\n    216 \n    217 \n\nValueError: could not convert string to float: 'detritus'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;34m\"\"\"Launch job\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_array\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, transformers, score_preds)\u001b[0m\n\u001b[1;32m    204\u001b[0m         assign_predictions(self.out_array, predictions,\n\u001b[0;32m--> 205\u001b[0;31m                            self.out_index, self.output_columns, n)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/_base_functions.py\u001b[0m in \u001b[0;36massign_predictions\u001b[0;34m(pred, p, tei, col, n)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'detritus'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Apr 30 18:15:58 2019\nPID: 541                                     Python 3.5.2: /usr/bin/python3\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('kneighborsclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>), ('kneighborsclassifier.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('decisiontreeclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>)])\n    131         transformers = self._load_preprocess(path)\n    132 \n    133         self._fit(transformers)\n    134 \n    135         if self.out_array is not None:\n--> 136             self._predict(transformers, self.scorer is not None)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n        self.scorer = make_scorer(f1_score, average=macro, labels=['An...llen' 'rods' 'silks'\n 'tempChaetoceros danicus'])\n    137 \n    138         o = IndexedEstimator(estimator=self.estimator,\n    139                              name=self.name_index,\n    140                              index=self.index,\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=True)\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n    204         assign_predictions(self.out_array, predictions,\n--> 205                            self.out_index, self.output_columns, n)\n        self.out_index = [(0, 9745), (97444, 107189)]\n        self.output_columns = 0\n        n = 194888\n    206 \n    207         # Score predictions if applicable\n    208         if score_preds:\n    209             self.score_ = score_predictions(\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/_base_functions.py in assign_predictions(pred=array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), p=array(['detritus', 'feces', 'badfocus (artefact)...s',\n       'detritus', 'detritus'], dtype=object), tei=[(0, 9745), (97444, 107189)], col=0, n=194888)\n    208                 idx = slice(tei[0] - r, tei[1] - r)\n    209         else:\n    210             idx = slice(tei[0] - r, tei[1] - r)\n    211 \n    212         if len(p.shape) == 1:\n--> 213             pred[idx, col] = p\n        pred = array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n        idx = array([     0,      1,      2, ..., 107186, 107187, 107188])\n        col = 0\n        p = array(['detritus', 'feces', 'badfocus (artefact)...s',\n       'detritus', 'detritus'], dtype=object)\n    214         else:\n    215             pred[(idx, slice(col, col + p.shape[1]))] = p\n    216 \n    217 \n\nValueError: could not convert string to float: 'detritus'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6f2e6ece3240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Attach the final meta estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0me_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m         with ParallelProcessing(self.backend, self.n_jobs,\n\u001b[1;32m    157\u001b[0m                                 max(self.verbose - 4, 0)) as manager:\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(self, caller, job, X, y, path, return_preds, warm_start, split, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             return_preds=return_preds, split=split, stack=True)\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, caller, out, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, task, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_prediction_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__threading__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__no_output__\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_feature_prop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/parallel/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, args, parallel)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         parallel(delayed(sublearner, not _threading)()\n\u001b[0;32m--> 152\u001b[0;31m                  \u001b[0;32mfor\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                  for sublearner in learner(args, 'main'))\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fbc64ca8270, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fbc64ca8270, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    340             raise RuntimeError('Event loop is running.')\n    341         self._set_coroutine_wrapper(self._debug)\n    342         self._thread_id = threading.get_ident()\n    343         try:\n    344             while True:\n--> 345                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    346                 if self._stopping:\n    347                     break\n    348         finally:\n    349             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1307                         logger.warning('Executing %s took %.3f seconds',\n   1308                                        _format_handle(handle), dt)\n   1309                 finally:\n   1310                     self._current_handle = None\n   1311             else:\n-> 1312                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(14, 1)>>\n   1313         handle = None  # Needed to break cycles when an exception occurs.\n   1314 \n   1315     def _set_coroutine_wrapper(self, enabled):\n   1316         try:\n\n...........................................................................\n/usr/lib/python3.5/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(14, 1)>)\n    120             self._callback = None\n    121             self._args = None\n    122 \n    123     def _run(self):\n    124         try:\n--> 125             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (14, 1)\n    126         except Exception as exc:\n    127             cb = _format_callback_source(self._callback, self._args)\n    128             msg = 'Exception in callback {}'.format(cb)\n    129             context = {\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=14, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 30, 18, 14, 36, 20273, tzinfo=tzlocal()), 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'session': '96576236-0499-4cf8-befb-bb24bd7109e0', 'username': '', 'version': '5.2'}, 'metadata': {'cellId': '02725818-9b2a-4fa3-81c8-d6c31092c1a1', 'deletedCells': ['7d83f08b-76d3-4762-9a57-3bc71993da33']}, 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'96576236-0499-4cf8-befb-bb24bd7109e0']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 30, 18, 14, 36, 20273, tzinfo=tzlocal()), 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'session': '96576236-0499-4cf8-befb-bb24bd7109e0', 'username': '', 'version': '5.2'}, 'metadata': {'cellId': '02725818-9b2a-4fa3-81c8-d6c31092c1a1', 'deletedCells': ['7d83f08b-76d3-4762-9a57-3bc71993da33']}, 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'96576236-0499-4cf8-befb-bb24bd7109e0'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 30, 18, 14, 36, 20273, tzinfo=tzlocal()), 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'session': '96576236-0499-4cf8-befb-bb24bd7109e0', 'username': '', 'version': '5.2'}, 'metadata': {'cellId': '02725818-9b2a-4fa3-81c8-d6c31092c1a1', 'deletedCells': ['7d83f08b-76d3-4762-9a57-3bc71993da33']}, 'msg_id': 'b4f3fa98-258a-4b01-89f7-5a66f740bfab', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-22-6f2e6ece3240>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fbbd7d46e80, executi...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fbbe151ca50, file \"<ipython-input-22-6f2e6ece3240>\", line 24>\n        result = <ExecutionResult object at 7fbbd7d46e80, executi...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fbbe151ca50, file \"<ipython-input-22-6f2e6ece3240>\", line 24>, result=<ExecutionResult object at 7fbbd7d46e80, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fbbe151ca50, file \"<ipython-input-22-6f2e6ece3240>\", line 24>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'In': ['', '# stacking \\nfrom mlens.ensemble import Subsemble', 'get_ipython().system(\"pip3 install -user \\'mlens\\'\")', 'get_ipython().system(\"pip3 install -user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens\\'\")', '# stacking \\nfrom mlens.ensemble import Subsemble', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'get_ipython().run_line_magic(\\'matplotlib\\', \\'inli...qdm\\n\\nbasepath = \"/mnt/datasets/plankton/flowcam/\"', \"nativeDF = pd.read_csv(basepath + 'features_nati...z')\\nlabelsDF = pd.read_csv(basepath + 'meta.csv')\", \"#print(nativeDF.isnull().sum().sort_values(ascen...rea',\\n                  'nb2_area', 'nb3_area', ]\", 'for col_name in native_nan_cols:\\n    nativeDF[co...sum().any())\\nprint(labelsDF.isnull().sum().any())', \"y = labelsDF['level2'] \\nX = nativeDF\", 'from sklearn.model_selection import train_test_s...X, y, test_size = test_size, random_state = seed)', 'from sklearn.metrics import accuracy_score, log_...og_cols)\\n    log = log.append(log_entry)\\n    \\nlog', \"def f1(y_test, pred):\\n    return f1_score(y_test, pred, average='macro', labels=np.unique(pred))\", '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', \"from mlens.metrics import make_scorer\\n\\nf1 = make...t, pred, average='macro', labels=np.unique(pred))\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {14:                Classifier   Accuracy   Log Loss ...PClassifier  36.055581  22.061722        0.219377}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Subsemble': <class 'mlens.ensemble.subsemble.Subsemble'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'In': ['', '# stacking \\nfrom mlens.ensemble import Subsemble', 'get_ipython().system(\"pip3 install -user \\'mlens\\'\")', 'get_ipython().system(\"pip3 install -user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens.ensemble\\'\")', 'get_ipython().system(\"pip3 install --user \\'mlens\\'\")', '# stacking \\nfrom mlens.ensemble import Subsemble', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', 'get_ipython().run_line_magic(\\'matplotlib\\', \\'inli...qdm\\n\\nbasepath = \"/mnt/datasets/plankton/flowcam/\"', \"nativeDF = pd.read_csv(basepath + 'features_nati...z')\\nlabelsDF = pd.read_csv(basepath + 'meta.csv')\", \"#print(nativeDF.isnull().sum().sort_values(ascen...rea',\\n                  'nb2_area', 'nb3_area', ]\", 'for col_name in native_nan_cols:\\n    nativeDF[co...sum().any())\\nprint(labelsDF.isnull().sum().any())', \"y = labelsDF['level2'] \\nX = nativeDF\", 'from sklearn.model_selection import train_test_s...X, y, test_size = test_size, random_state = seed)', 'from sklearn.metrics import accuracy_score, log_...og_cols)\\n    log = log.append(log_entry)\\n    \\nlog', \"def f1(y_test, pred):\\n    return f1_score(y_test, pred, average='macro', labels=np.unique(pred))\", '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', '# stacking \\nfrom mlens.ensemble import Subsemble...nique(e_preds))\\nprint(\"Stacked F1 Score: \", e_f1)', \"from mlens.metrics import make_scorer\\n\\nf1 = make...t, pred, average='macro', labels=np.unique(pred))\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {14:                Classifier   Accuracy   Log Loss ...PClassifier  36.055581  22.061722        0.219377}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Subsemble': <class 'mlens.ensemble.subsemble.Subsemble'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/mnt/workspace/AML-2019/Challenges/4_Plankton/<ipython-input-22-6f2e6ece3240> in <module>()\n     19 \n     20 # Build the first layer\n     21 ensemble.add([rf, kn, dt, mlpc])\n     22 # Attach the final meta estimator\n     23 ensemble.add_meta(lr)\n---> 24 ensemble.fit(X_train, y_train)\n     25 e_preds = ensemble.predict(X_test)\n     26 \n     27 e_f1 = f1_score(y_test, e_preds, average='macro', labels=np.unique(e_preds))\n     28 print(\"Stacked F1 Score: \", e_f1)\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=Subsemble(array_check=None, backend=None, folds=...oceros danicus']),\n     shuffle=False, verbose=2), X=             objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], y=133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object, **kwargs={})\n    509             return self\n    510 \n    511         if self.model_selection:\n    512             self._id_train.fit(X)\n    513 \n--> 514         out = self._backend.fit(X, y, **kwargs)\n        out = undefined\n        self._backend.fit = <bound method Sequential.fit of Sequential(backe...nsformers=[])],\n   verbose=1)],\n      verbose=2)>\n        X =              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns]\n        y = 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object\n        kwargs = {}\n    515         if out is not self._backend:\n    516             # fit_transform\n    517             return out\n    518         else:\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), X=             objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], y=133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object, **kwargs={})\n    153 \n    154         f, t0 = print_job(self, \"Fitting\")\n    155 \n    156         with ParallelProcessing(self.backend, self.n_jobs,\n    157                                 max(self.verbose - 4, 0)) as manager:\n--> 158             out = manager.stack(self, 'fit', X, y, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        X =              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns]\n        y = 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object\n        kwargs = {}\n    159 \n    160         if self.verbose:\n    161             print_time(t0, \"{:<35}\".format(\"Fit complete\"), file=f)\n    162 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), job='fit', X=             objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], y=133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object, path=None, return_preds=False, warm_start=False, split=True, **kwargs={})\n    668             Prediction array(s).\n    669         \"\"\"\n    670         out = self.initialize(\n    671             job=job, X=X, y=y, path=path, warm_start=warm_start,\n    672             return_preds=return_preds, split=split, stack=True)\n--> 673         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        out = {}\n        kwargs = {}\n    674 \n    675     def process(self, caller, out, **kwargs):\n    676         \"\"\"Process job.\n    677 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), out=None, **kwargs={})\n    713                       backend=self.backend) as parallel:\n    714 \n    715             for task in caller:\n    716                 self.job.clear()\n    717 \n--> 718                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    719 \n    720                 if task.name in return_names:\n    721                     out.append(self.get_preds(dtype=_dtype(task)))\n    722 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), parallel=Parallel(n_jobs=-1), **kwargs={})\n    734         task.setup(self.job.predict_in, self.job.targets, self.job.job)\n    735 \n    736         if not task.__no_output__:\n    737             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    738 \n--> 739         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    740 \n    741         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    742             self._propagate_features(task)\n    743 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), args={'auxiliary': {'P': None, 'X':              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], 'y': 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object}, 'dir': [('kneighborsclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>), ('kneighborsclassifier.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('decisiontreeclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>), ('decisiontreeclassifier.0.0', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'X':              objid     area  meanimagegrey    me...7665      21.662651  \n\n[194888 rows x 65 columns], 'y': 133736                          detritus\n9746   ...ritus\nName: level2, Length: 194888, dtype: object}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus'])), Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus'])), Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus'])), Learner(attr='predict', backend='threading', dty...len' 'rods' 'silks'\n 'tempChaetoceros danicus']))]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Apr 30 18:15:58 2019\nPID: 541                                     Python 3.5.2: /usr/bin/python3\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('kneighborsclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>), ('kneighborsclassifier.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('decisiontreeclassifier.1.0', <mlens.parallel.learner.IndexedEstimator object>)])\n    131         transformers = self._load_preprocess(path)\n    132 \n    133         self._fit(transformers)\n    134 \n    135         if self.out_array is not None:\n--> 136             self._predict(transformers, self.scorer is not None)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n        self.scorer = make_scorer(f1_score, average=macro, labels=['An...llen' 'rods' 'silks'\n 'tempChaetoceros danicus'])\n    137 \n    138         o = IndexedEstimator(estimator=self.estimator,\n    139                              name=self.name_index,\n    140                              index=self.index,\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=True)\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n    204         assign_predictions(self.out_array, predictions,\n--> 205                            self.out_index, self.output_columns, n)\n        self.out_index = [(0, 9745), (97444, 107189)]\n        self.output_columns = 0\n        n = 194888\n    206 \n    207         # Score predictions if applicable\n    208         if score_preds:\n    209             self.score_ = score_predictions(\n\n...........................................................................\n/mnt/workspace/.local/lib/python3.5/site-packages/mlens/parallel/_base_functions.py in assign_predictions(pred=array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), p=array(['detritus', 'feces', 'badfocus (artefact)...s',\n       'detritus', 'detritus'], dtype=object), tei=[(0, 9745), (97444, 107189)], col=0, n=194888)\n    208                 idx = slice(tei[0] - r, tei[1] - r)\n    209         else:\n    210             idx = slice(tei[0] - r, tei[1] - r)\n    211 \n    212         if len(p.shape) == 1:\n--> 213             pred[idx, col] = p\n        pred = array([[0., 0., 0., ..., 0., 0., 0.],\n       [0....   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n        idx = array([     0,      1,      2, ..., 107186, 107187, 107188])\n        col = 0\n        p = array(['detritus', 'feces', 'badfocus (artefact)...s',\n       'detritus', 'detritus'], dtype=object)\n    214         else:\n    215             pred[(idx, slice(col, col + p.shape[1]))] = p\n    216 \n    217 \n\nValueError: could not convert string to float: 'detritus'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# stacking \n",
    "from mlens.ensemble import Subsemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlens.metrics import make_scorer\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy')\n",
    "kn = KNeighborsClassifier(3)\n",
    "dt = DecisionTreeClassifier()\n",
    "mlpc = MLPClassifier(alpha=1)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "seed = 42\n",
    "\n",
    "\n",
    "f1 = make_scorer(f1_score, greater_is_better=True, average='macro', labels=np.unique(y_test))\n",
    "\n",
    "ensemble = Subsemble(scorer = f1, random_state=seed, folds=10, verbose = 2)\n",
    "\n",
    "# Build the first layer\n",
    "ensemble.add([rf, kn, dt, mlpc])\n",
    "# Attach the final meta estimator\n",
    "ensemble.add_meta(lr)\n",
    "ensemble.fit(X_train, y_train)\n",
    "e_preds = ensemble.predict(X_test)\n",
    "\n",
    "e_f1 = f1_score(y_test, e_preds, average='macro', labels=np.unique(e_preds))\n",
    "print(\"Stacked F1 Score: \", e_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
